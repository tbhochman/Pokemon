{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mStpGvEbPhUa"
   },
   "source": [
    "## Preliminary analysis\n",
    "\n",
    "This notebook analyzes the MTA subway data for the week of June 10-17, 2017 that can be found here:\n",
    "\n",
    "http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "1.Download that SAME file and read it in below. View the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "dC6ij1oWPhUb",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 110] Connection timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db93b802893d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://web.mta.info/developers/data/nyct/turnstile/turnstile_170617.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 413\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_170617.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ORJ0mTH0PhUe"
   },
   "source": [
    "2.What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lI12wZTDPhUf"
   },
   "outputs": [
   ],
   "source": [
    "#insert 2\n",
    "file.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "j5vI0VWzPhUj"
   },
   "source": [
    "3.We can see that there is a lot of whitespace at the end of the exits column name. Let's strip that whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "VPkcWYbdPhUk"
   },
   "outputs": [
   ],
   "source": [
    "#insert 3\n",
    "file.columns = file.columns.str.strip()\n",
    "file.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "hpp8WuvNPhUm"
   },
   "source": [
    "4.How big is the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Q8wuU_CRPhUn"
   },
   "outputs": [
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Cs09G8y-PhUp"
   },
   "source": [
    "5.How many unique stations are there? What are they? Answer each of these questions in one line each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "2NYLAovdPhUq"
   },
   "outputs": [
   ],
   "source": [
    "#insert 5\n",
    "# file.groupby(['STATION', 'C/A', 'UNIT', 'SCP']).count()\n",
    "print(len(set(file.STATION)))\n",
    "print('The stations are:', set(file.STATION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "cHoomcKyPhUu"
   },
   "source": [
    "6.Okay, so we understand what station represents. But what the heck are C/A, UNIT, and SCP? Keep in mind that in the larger stations, you might have multiple areas within one station that look like this:\n",
    "\n",
    "<img src=\"image.jpg\" style=\"width: 300px;\"/>\n",
    "\n",
    "Further complicating things, there are a few station names like 14TH ST that refer to more than one station location along that street.\n",
    "\n",
    "This data set is not very well documented. Welcome to the joys of real world data science!!!\n",
    "\n",
    "Read the following two links carefully to see other people's confusion and what information they have been able to gather:\n",
    "\n",
    "https://groups.google.com/forum/#!topic/mtadeveloperresources/AMVx2WUY9iI\n",
    "\n",
    "https://groups.google.com/forum/#!searchin/mtadeveloperresources/%22remote$20unit%22%7Csort:relevance/mtadeveloperresources/z8l3ZU9cY6Y/OFlHGkFAimQJ\n",
    "\n",
    "It sounds like each C/A + UNIT + SCP + STATION combo refers to a single turnstile. How many unique turnstiles are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "zimRzTJMPhUu"
   },
   "outputs": [
   ],
   "source": [
    "#insert 6\n",
    "print(len(file.groupby(['STATION', 'C/A', 'UNIT', 'SCP']).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5SJoHrr4PhUx"
   },
   "source": [
    "7.What data types are each of the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "S1jYB-EUPhUy"
   },
   "outputs": [
   ],
   "source": [
    "#insert 7\n",
    "file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "gIc54DxNPhU2"
   },
   "source": [
    "8.We can see that the exits and entries are treated as integers but the others are all treated as objects (strings). Overwrite the time column so that it is a datetime object containing the combined date and time column info (so that the times have a chronological order). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jzIxrOlYPhU3"
   },
   "outputs": [
   ],
   "source": [
    "#insert 8\n",
    "file.TIME = pd.to_datetime(file.DATE + ' ' + file.TIME, format = '%m/%d/%Y %H:%M:%S')\n",
    "del file['DATE']\n",
    "file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "_aYeYy02PhU6"
   },
   "source": [
    "9.What is the earliest and latest date in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gV_u3A4lPhU6"
   },
   "outputs": [
   ],
   "source": [
    "#insert 9\n",
    "print(file.TIME.min())\n",
    "print(file.TIME.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "LZT4y83fPhU8"
   },
   "source": [
    "10.If we wanted to only look at the 34st Street Penn Station stop on 6/12/2017, what would we type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "F6LMCUSFPhU9"
   },
   "outputs": [
   ],
   "source": [
    "#insert 10\n",
    "import datetime\n",
    "date = datetime.date(year=2017, month=6, day=12)\n",
    "file[(file['STATION'] == '34 ST-PENN STA') & (file['TIME'] == date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Nn50RQAgPhU_"
   },
   "source": [
    "11.Create a dictionary called bigDict. It should contain a nested set of keys and values. The outermost key should be the tuple (C/A,UNIT,STATION) and its value should itself be a dictionary with the SCP as the key and a list of (TIME, EXITS) tuples as its values. The purpose of this section is to prepare data for later uses. It should take a little while to finish running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bigDict = {}\n",
    "for i,row in file.iterrows():\n",
    "    if (row['C/A'], row['UNIT'], row['STATION']) in bigDict:\n",
    "        if row['SCP'] in bigDict[(row['C/A'], row['UNIT'], row['STATION'])]:\n",
    "            bigDict[(row['C/A'], row['UNIT'], row['STATION'])][row['SCP']].append((row['datetime'], row['EXITS']))\n",
    "        else:\n",
    "            bigDict[(row['C/A'], row['UNIT'], row['STATION'])][row['SCP']] = [(row['datetime'], row['EXITS'])]\n",
    "    else:\n",
    "        bigDict[(row['C/A'], row['UNIT'], row['STATION'])] = {row['SCP'] : [(row['datetime'], row['EXITS'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "qt7jRerOPhVC"
   },
   "source": [
    "12.As an example, use the bigDict to view all of the turnstile data located at the('A037', 'R170', '14 ST-UNION SQ') area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ZSuarWASPhVC"
   },
   "outputs": [
   ],
   "source": [
    "#insert 12\n",
    "print(bigDict[('A037', 'R170', '14 ST-UNION SQ')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "zRotAgYHPhVF"
   },
   "source": [
    "13.Create a function called inspection that takes in the (C/A,UNIT,STATION) tuple and SCP value and plots the exit counter data versus time. \n",
    "\n",
    "For example, the input of \n",
    "```python\n",
    "inspection(('A037', 'R170', '14 ST-UNION SQ'), '05-00-00')\n",
    "```\n",
    "should produce an upward trending plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "GzHd5fJbPhVG"
   },
   "outputs": [
   ],
   "source": [
    "#insert 13\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def inspection(bigDict_tuple, SCP):\n",
    "    times = []\n",
    "    exits = []\n",
    "    for time, count in bigDict[bigDict_tuple][SCP]:\n",
    "        times.append(time)\n",
    "        exits.append(count)\n",
    "    plt.plot(times, exits)\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Exit Count')\n",
    "    plt.title('People exited at a given time')\n",
    "\n",
    "inspection(('A037', 'R170', '14 ST-UNION SQ'), '05-00-00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "4PvO-TRJPhVI"
   },
   "source": [
    "## Finding Data Errors\n",
    "14.Due to bugs in MTA data, we will need to remove \"incorrect\" data. First, find the incorrect data by figuring out which turnstile counters aren't going strictly upwards. How many of these incorrect data values are there? Create a smaller dictionary callled \"trouble\" that contains the troublesome data from the bigDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "xp_22cNoPhVJ"
   },
   "outputs": [
   ],
   "source": [
    "#insert 14\n",
    "trouble = {}\n",
    "for st,stv in bigDict.items():\n",
    "    for scp,lst in stv.items():\n",
    "        #Cleaning in Each LIST of turnstile\n",
    "        toDel = []\n",
    "        n = len(lst)\n",
    "        lst.sort()\n",
    "        for i in range(1,n-1):\n",
    "            if(lst[i-1][1]<=lst[i][1] and lst[i][1]<=lst[i+1][1]): #What we expected Data to be (Non-Decreasing)\n",
    "                continue\n",
    "            key = (st,scp)\n",
    "            trouble[key] = trouble.get(key,0)+1\n",
    "print(\"Trouble List: \",len(trouble.keys()))\n",
    "for k,v in trouble.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5ABIdqxlPhVL"
   },
   "source": [
    "15.Using the troublesome dictionary and your inspection plotting function, plot all of the troublesome data. There are several different types of errors. What do you think is causing each type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "dnxCjxB5PhVM"
   },
   "outputs": [
   ],
   "source": [
    "#insert 15\n",
    "for station, SCP_dict in trouble.items():\n",
    "    inspection(station[0], station[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ctWRbA6NPhVR"
   },
   "source": [
    "## Data Cleanup\n",
    "There are three types of mistakes: decreasing, garbage values, and turnstile resets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "yYQ1t9ELPhVS"
   },
   "source": [
    "#### Mistake Type I: Monotone but Decreasing - To fix this, we reflect the data. \n",
    "\n",
    "16.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "RZrRM7QZPhVT",
    "outputId": "6cec83ae-f11c-49a8-d83f-1eebc3812690"
   },
   "outputs": [
   ],
   "source": [
    "def isMonotoneDecrease(tup):\n",
    "    '''Input: Tuple of (Station,SCP). \n",
    "    Output: True if this SCP has monotone property, but decreasing, False otherwise.'''\n",
    "    n = len(bigDict[tup[0]][tup[1]])\n",
    "    for i in range(n-1):\n",
    "        if(bigDict[tup[0]][tup[1]][i+1][1]>bigDict[tup[0]][tup[1]][i][1]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def fixMonotoneDecrease(tup):\n",
    "    '''reflects the data to fix it'''\n",
    "    n = len(bigDict[tup[0]][tup[1]])\n",
    "    for i in range(n):\n",
    "        bigDict[tup[0]][tup[1]][i] = (bigDict[tup[0]][tup[1]][i][0],(-1)*bigDict[tup[0]][tup[1]][i][1])\n",
    "    \n",
    "\n",
    "monotoneDecreaseList = []\n",
    "for k in trouble:\n",
    "    if(isMonotoneDecrease(k)):\n",
    "        monotoneDecreaseList.append(k)\n",
    "print(\"Total Monotone Decrease:\",len(monotoneDecreaseList))\n",
    "for k in monotoneDecreaseList:\n",
    "    fixMonotoneDecrease(k)\n",
    "print(\"Problem Fixed!\")\n",
    "\n",
    "for k in trouble:\n",
    "    if(isMonotoneDecrease(k)):\n",
    "        monotoneDecreaseList.append(k)\n",
    "print(\"Total Monotone Decrease:\",len(monotoneDecreaseList))\n",
    "for k in monotoneDecreaseList:\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "rtUwUo-cPhVa"
   },
   "source": [
    "#### Mistake Type II: Garbage Value - To fix this, remove the garbage value\n",
    "\n",
    "17.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Yosg1ex6PhVa",
    "outputId": "fe3ac72a-5246-46ed-cbf5-ce7076af2185"
   },
   "outputs": [
   ],
   "source": [
    "def garbageEliminator(tup):\n",
    "    '''removes nonsensical isolated points'''\n",
    "    n = len(bigDict[tup[0]][tup[1]])\n",
    "    toDel = []\n",
    "    for i in range(1,n-1):\n",
    "        if((bigDict[tup[0]][tup[1]][i-1][1]>bigDict[tup[0]][tup[1]][i+1][1])):\n",
    "            continue\n",
    "        if((bigDict[tup[0]][tup[1]][i-1][1]<=bigDict[tup[0]][tup[1]][i][1]) and (bigDict[tup[0]][tup[1]][i][1]<=bigDict[tup[0]][tup[1]][i+1][1])):\n",
    "            continue\n",
    "        toDel.append(bigDict[tup[0]][tup[1]][i])\n",
    "    #Deletion Process\n",
    "    if(len(toDel)==0):\n",
    "        return 0\n",
    "    for k in toDel:\n",
    "        bigDict[tup[0]][tup[1]].remove(k)\n",
    "    return 1\n",
    "\n",
    "\n",
    "#Driver\n",
    "cnt = 0\n",
    "healList = []\n",
    "for k in trouble:\n",
    "    if(garbageEliminator(k)):\n",
    "        healList.append(k)\n",
    "print(\"Garbage Removed:\",len(healList))\n",
    "for k in healList:\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mwwLsrOlPhVd"
   },
   "source": [
    "#### Mistake Type III: Turnstile Reset - To fix this, shift the data upwards.\n",
    "\n",
    "18.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "_Q9Uvl-APhVd",
    "outputId": "e268af6a-263e-48a8-b44e-e883ba227697"
   },
   "outputs": [
   ],
   "source": [
    "def dealingWithReset(tup):\n",
    "    '''for counters that are reset, we fix the data by shifting it upwards'''\n",
    "    sta = tup[0]\n",
    "    tsl = tup[1]\n",
    "    n = len(bigDict[sta][tsl])\n",
    "    #Detecting Part\n",
    "    resetPoint = [] # it means (i,i+1) is reset\n",
    "    resetSet = []\n",
    "    for i in range(1,n-2):\n",
    "        if(bigDict[sta][tsl][i][1]<=bigDict[sta][tsl][i+1][1]):\n",
    "            continue #We don't need to change this one\n",
    "        resetPoint.append(i)\n",
    "    #Fixing Part\n",
    "    resetSet = set(resetPoint)\n",
    "    cumulative = 0\n",
    "    for i in range(n-2):\n",
    "        if(i not in resetSet):\n",
    "            bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "            continue\n",
    "        #Problem\n",
    "        expected = (bigDict[sta][tsl][i][1]-bigDict[sta][tsl][i-1][1])+ (bigDict[sta][tsl][i+2][1]-bigDict[sta][tsl][i+1][1])\n",
    "        expected = int(expected/2)\n",
    "        shift = (bigDict[sta][tsl][i][1]+expected)-bigDict[sta][tsl][i+1][1]\n",
    "        cumulative = shift\n",
    "    for i in range(n-2,n):\n",
    "        bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "    #Done!\n",
    "    \n",
    "#Test Usage\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')\n",
    "dealingWithReset((('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00'))\n",
    "print(\"Cleaned\")\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "A4YofuN7PhVh"
   },
   "source": [
    "## Overall Cleaning Process\n",
    "19.This next cell does all of the previous cleanup in one cell. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PmQDV_w6PhVi",
    "outputId": "164fc903-a25f-424d-9ea4-541062039093"
   },
   "outputs": [
   ],
   "source": [
    "toClean = {}\n",
    "for st,stv in bigDict.items():\n",
    "    for scp,lst in stv.items():\n",
    "        #Cleaning in Each LIST of turnstile\n",
    "        toDel = []\n",
    "        n = len(lst)\n",
    "        lst.sort()\n",
    "        for i in range(1,n-1):\n",
    "            if(lst[i-1][1]<=lst[i][1] and lst[i][1]<=lst[i+1][1]): #What we expected Data to be (Non-Decreasing)\n",
    "                continue\n",
    "\n",
    "            key = (st,scp)\n",
    "            toClean[key] = trouble.get(key,0)+1\n",
    "            \n",
    "for k in toClean.keys():\n",
    "    if(isMonotoneDecrease(k)):\n",
    "        fixMonotoneDecrease(k)\n",
    "    garbageEliminator(k)\n",
    "    dealingWithReset(k)\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "B-eaK9XNPhVk"
   },
   "source": [
    "20.Which troublesome stations are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Bk80qJWkPhVl",
    "outputId": "c61990cc-3de6-4bf0-8312-84dab104d40e"
   },
   "outputs": [
   ],
   "source": [
    "trouble = {}\n",
    "for st,stv in bigDict.items():\n",
    "    for scp,lst in stv.items():\n",
    "        #Cleaning in Each LIST of turnstile\n",
    "        toDel = []\n",
    "        n = len(lst)\n",
    "        lst.sort()\n",
    "        for i in range(1,n-1):\n",
    "            if(lst[i-1][1]<=lst[i][1] and lst[i][1]<=lst[i+1][1]): #What we expected Data to be (Non-Decreasing)\n",
    "                continue\n",
    "                \n",
    "            key = (st,scp)\n",
    "            trouble[key] = trouble.get(key,0)+1\n",
    "print(\"Trouble List: \",len(trouble.keys()))\n",
    "for k,v in trouble.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "3AKy82ddPhVo"
   },
   "source": [
    "21.Delete these two keys from bigDict manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "J-Qbu3zbPhVq"
   },
   "outputs": [
   ],
   "source": [
    "#insert 21\n",
    "del bigDict[('PTH11', 'R545', '14TH STREET')]['00-00-03']\n",
    "del bigDict[('R240', 'R047', 'GRD CNTRL-42 ST')]['00-00-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mYiZoVzLPhVs"
   },
   "source": [
    "22.The data is now all cleaned, so let's save it so that we don't have to run all of the above code every time. Use the pickle package to save bigDict as an \"MTAdict.pkl\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "BaH-GS-5PhVt"
   },
   "outputs": [
   ],
   "source": [
    "#insert 22\n",
    "import pickle\n",
    "with open('MTAdict.pkl', 'wb') as file:\n",
    "    pickle.dump(bigDict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KQeRQaOtPhVw"
   },
   "source": [
    "# --At this point, the data is ready to use and so we are ready for data analysis.--\n",
    "23.Let's read the cleaned data file back in and save it as bigDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gll6KAACPhVw"
   },
   "outputs": [
   ],
   "source": [
    "#insert 23\n",
    "file = open('MTAdict.pkl', 'rb')\n",
    "bigDict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "QqgMHi0GPhVy"
   },
   "source": [
    "24.Create a function called turnstileRiders that takes in a single turnstile's date/exit info and a start and endtime (in datetime format) and returns the number of riders through that turnstile within that time period. As an extension, you may want to use a linear approximation in the case of incomplete information. \n",
    "\n",
    "For instance, the input \n",
    "```python\n",
    "t1 = dt.strptime(\"2017-06-12 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "t2 = dt.strptime(\"2017-06-13 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "turnstileRiders(bigDict[('R204', 'R043', 'WALL ST')][\"02-00-00\"],t1,t2)\n",
    "```\n",
    "\n",
    "should output 1419 riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "O3WxVxloPhVz"
   },
   "outputs": [
   ],
   "source": [
    "#insert 24\n",
    "from datetime import datetime\n",
    "def turnstileRiders(station, t1, t2):\n",
    "    if t1 < station[0][0]:\n",
    "        count1 = station[0][1]\n",
    "    for time, count in station:\n",
    "        if t1 >= time:\n",
    "            count1 = count\n",
    "        if t2 >= time:\n",
    "            count2 = count\n",
    "    return count2 - count1\n",
    "\n",
    "t1 = datetime.strptime(\"2017-06-12 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "t2 = datetime.strptime(\"2017-06-13 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "turnstileRiders(bigDict[('R204', 'R043', 'WALL ST')][\"02-00-00\"],t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "E25eeOU3PhV2"
   },
   "source": [
    "25.Create a function called stationRiders that calls the turnstileRiders function for each turnstile in a  (C/A,UNIT,STATION) station area and tallies all of the riders through that area between two times.\n",
    "\n",
    "For example, an input of \n",
    "```python\n",
    "getStationRangeRider(bigDict[('R204', 'R043', 'WALL ST')],dt(2017,6,12,0,0,0),dt(2017,6,13,0,0,0))\n",
    "```\n",
    "should output 9507 riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "FyVMIPztPhV2"
   },
   "outputs": [
   ],
   "source": [
    "#insert 25\n",
    "from datetime import datetime as dt\n",
    "def getStationRangeRider(station, t1, t2):\n",
    "    total = 0\n",
    "    for scp, times_list in station.items():\n",
    "        total += turnstileRiders(times_list, t1, t2)\n",
    "    return total\n",
    "\n",
    "getStationRangeRider(bigDict[('R204', 'R043', 'WALL ST')],dt(2017,6,12,0,0,0),dt(2017,6,13,0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Q-rMHLJOPhV5"
   },
   "source": [
    "26.There are still several station areas within a station. Make a plot of the day of the week versus the number of total station rider exits for the ENTIRE Wall St station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3Peae4oHPhV5"
   },
   "outputs": [
   ],
   "source": [
    "#insert 26\n",
    "import datetime as dt\n",
    "t1 = dt.datetime(2017,6,9,0,0,0)\n",
    "day_count = {}\n",
    "for station in bigDict:\n",
    "    if 'WALL ST' == station[2]:\n",
    "#         print(station)\n",
    "        for i in range(7):\n",
    "            t1 += dt.timedelta(days = 1)\n",
    "            t2 = t1 + dt.timedelta(days = 1)\n",
    "#             print(t1, t2)\n",
    "            day = t1.strftime('%a')\n",
    "            if day in day_count:\n",
    "                day_count[day] += getStationRangeRider(bigDict[station],t1,t2)\n",
    "            else:\n",
    "                day_count[day] = getStationRangeRider(bigDict[station],t1,t2)\n",
    "print(day_count)\n",
    "days = []\n",
    "for day, count in day_count.items():\n",
    "    print(day)\n",
    "    for person in range(count):\n",
    "        days.append(day)\n",
    "plt.hist(days, bins = np.arange(-0.5, 6.6, 1), rwidth = 0.8)\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Number of people')\n",
    "plt.title('Number of people per day on Wall St')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "OQK29674PhV7"
   },
   "source": [
    "27.Sort by busiest station areas during 6/12 midnight - 6/13 midnight in descending order by creating a list of sorted tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tw8fwI_BPhV8"
   },
   "outputs": [
   ],
   "source": [
    "#insert 27\n",
    "countsstations = []\n",
    "t1 = dt.datetime(2017,6,12,0,0,0)\n",
    "t2 = t1 + dt.timedelta(days = 1)\n",
    "for station in bigDict:\n",
    "    try:\n",
    "        countsstations.append((getStationRangeRider(bigDict[station],t1, t2), station))\n",
    "    except:\n",
    "        print(station)\n",
    "print(sorted(countsstations, reverse = True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "VDOq0JHPPhV_"
   },
   "source": [
    "28.Make a dictionary called total_dict that contains the station name as its key and the total number of riders through all of its station areas between 6/12-6/13 as its value. Then create a sorted list of tuples to view the busiest stations on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "96J5DK0ePhWA"
   },
   "outputs": [
   ],
   "source": [
    "#insert 28\n",
    "stations_counts = {}\n",
    "t1 = dt.datetime(2017,6,12,0,0,0)\n",
    "t2 = t1 + dt.timedelta(days = 1)\n",
    "for station in bigDict:\n",
    "    try:\n",
    "        if station[2] in stations_counts:\n",
    "            stations_counts[station[2]] += getStationRangeRider(bigDict[station],t1, t2)\n",
    "        else:\n",
    "            stations_counts[station[2]] = getStationRangeRider(bigDict[station],t1, t2)\n",
    "    except:\n",
    "        print(station)\n",
    "counts_stations = []\n",
    "for station, count in stations_counts.items():\n",
    "    counts_stations.append((count, station))\n",
    "print(sorted(counts_stations, reverse = True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "kB0JnTbePhWB"
   },
   "source": [
    "29.Make a histogram of those station totals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "q4Q7Uzc8PhWC"
   },
   "outputs": [
   ],
   "source": [
    "#insert 29\n",
    "totals = []\n",
    "counts_stations.sort(reverse = True)\n",
    "for count, station in counts_stations[:5]:\n",
    "    for each_one in range(count):\n",
    "        totals.append(station)\n",
    "plt.hist(totals, bins = np.arange(-0.5, 5.6, 1), rwidth = 0.5)\n",
    "plt.xticks(fontsize = 6)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('People')\n",
    "plt.title('The most populous stations on 6/12/17')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "CtbpBxyRPhWE"
   },
   "source": [
    "30.Create a commuter index to be the average weekday exits divided by the sum of the avg weekday exits + avg weekend exits. To do this, first make a function called isWeekday that returns True if the datetime input is a weekday and False if it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MIHgElRQPhWE"
   },
   "outputs": [
   ],
   "source": [
    "#insert 31\n",
    "def isWeekday(time):\n",
    "    if time.weekday() <= 4:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "z-07SD3SPhWG"
   },
   "source": [
    "31.Make a function called commuterIndex that inputs a (C/A,UNIT,STATION) tuple and outputs its commuter index. \n",
    "\n",
    "For example, the output of \n",
    "```python\n",
    "getCommuteIndex(('PTH11', 'R545', '14TH STREET'))\n",
    "```\n",
    "should be 0.663."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JbZfNH0SPhWI"
   },
   "outputs": [
   ],
   "source": [
    "#insert 31\n",
    "def getCommuteIndex(station):\n",
    "    t1 = dt.datetime(2017,6,9,0,0,0)\n",
    "    weekday_exits = 0\n",
    "    weekend_exits = 0\n",
    "    for i in range(7):\n",
    "        t1 += dt.timedelta(days = 1)\n",
    "        t2 = t1 + dt.timedelta(days = 1)\n",
    "#         print(t1, t2, isWeekday(t1))\n",
    "        if isWeekday(t1):\n",
    "#             print('adding to weekday_exits')\n",
    "            weekday_exits += getStationRangeRider(bigDict[station], t1, t2)\n",
    "        else:\n",
    "            weekend_exits += getStationRangeRider(bigDict[station], t1, t2)\n",
    "    return weekday_exits / (weekday_exits + weekend_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "UQ80WNkhPhWK"
   },
   "source": [
    "32.Create a sorted list of tuples in descending order containing the commuter index and the station area tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Y2Bu9CROPhWK"
   },
   "outputs": [
   ],
   "source": [
    "#insert 32\n",
    "tuple_list = []\n",
    "for station in bigDict:\n",
    "    try:\n",
    "        tuple_list.append((getCommuteIndex(station), station))\n",
    "    except:\n",
    "        print(station, 'is a problem')\n",
    "tuple_list.sort(reverse = True)\n",
    "print(tuple_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "NsOCaBkdPhWP"
   },
   "source": [
    "33.Remember that there are still several station areas within each station. Let's get all of the commuter indexes for each station area and then take the median of that commuter index to assign to the entire station. Create a sorted list of tuples in descending order containing the median commuter index and the station name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ep_Wnvf0PhWQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuple_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-79c6af26bcac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#insert 33\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstation_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuple_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstation_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstation_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuple_list' is not defined"
     ]
    }
   ],
   "source": [
    "#insert 33\n",
    "station_dict = {}\n",
    "for index, station in tuple_list:\n",
    "    if station[2] in station_dict:\n",
    "        station_dict[station[2]].append(index)\n",
    "    else:\n",
    "        station_dict[station[2]] = [index]\n",
    "new_tuple_list = []\n",
    "for station, indexes in station_dict.items():\n",
    "    new_tuple_list.append((np.median(indexes), station))\n",
    "new_tuple_list.sort(reverse = True)\n",
    "print(new_tuple_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "BrUye94NPhWT"
   },
   "source": [
    "### How can you use what you have done so far to make decisions about MTA advertising???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "tuple_list = []\n",
    "for station in bigDict:\n",
    "    try:\n",
    "        tuple_list.append((getCommuteIndex(station), station))\n",
    "    except:\n",
    "        print(station, 'is a problem')\n",
    "tuple_list.sort(reverse = True)\n",
    "print(tuple_list[:10])\n",
    "new_tuples = {}\n",
    "for count, station in tuple_list:\n",
    "    if station[2] in new_tuples:\n",
    "        new_tuples[station[2]].append(count)\n",
    "    else:\n",
    "        new_tuples[station[2]] = [count]\n",
    "new_tuples_list = []\n",
    "for station, counts in new_tuples.items():\n",
    "    new_tuples_list.append((np.average(counts), station))\n",
    "print(sorted(new_tuples_list, reverse = True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def turnstileRiders(station, t1, t2):\n",
    "    if t1 < station[0][0]:\n",
    "        count1 = station[0][1]\n",
    "    for time, count in station:\n",
    "#         print(time)\n",
    "        if t1 >= time:\n",
    "            count1 = count\n",
    "        if t2 >= time:\n",
    "            count2 = count\n",
    "    return count2 - count1\n",
    "\n",
    "\n",
    "# def turnstileRiders(turnstileList,startTime,endTime):\n",
    "#     ret = 0 #Return Value\n",
    "#     n = len(turnstileList)\n",
    "#     totalTime = endTime-startTime\n",
    "#     #print(\"Total Time:\",totalTime) #Debugging Purpose\n",
    "#     for i in range(n-1): #A list of N items has (N-1) consecutive pairs\n",
    "#         ti = turnstileList[i][0]\n",
    "#         tf = turnstileList[i+1][0]\n",
    "#         if((tf<startTime) or (ti>endTime)):\n",
    "#             continue #Non-overlap Time Segment\n",
    "#         #Overlapping Time\n",
    "#         segmentTime = min(tf,endTime) - max(ti,startTime)\n",
    "#         fullSegment = tf-ti\n",
    "#         if(fullSegment==noDay): #Dealing with Bug\n",
    "#             return 0\n",
    "#         weight = segmentTime/fullSegment\n",
    "#         peopleCount = turnstileList[i+1][1]-turnstileList[i][1]\n",
    "#         peopleCount = cleanPeople(peopleCount)\n",
    "#         #print(\"Considering\",ti,\"to\",tf,\"Weight:\",weight,\"Riders:\",peopleCount) #Debugging Purpose\n",
    "#         ret+= (weight)*peopleCount\n",
    "#     return int(ret)\n",
    "\n",
    "\n",
    "t1 = datetime.strptime(\"2017-06-12 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "t2 = datetime.strptime(\"2017-06-13 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "print(turnstileRiders(bigDict[('R204', 'R043', 'WALL ST')][\"02-00-00\"],t1,t2))\n",
    "\n",
    "import datetime as dt\n",
    "def getStationRangeRider(station, t1, t2):\n",
    "    total = 0\n",
    "    for scp, times_list in station.items():\n",
    "        total += turnstileRiders(times_list, t1, t2)\n",
    "    return total\n",
    "\n",
    "print(getStationRangeRider(bigDict[('R204', 'R043', 'WALL ST')],dt.datetime(2017,6,12,0,0,0),dt.datetime(2017,6,13,0,0,0)))\n",
    "\n",
    "\n",
    "def isWeekday(time):\n",
    "    if time.weekday() <= 4:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getCommuteIndex(station):\n",
    "    t1 = dt.datetime(2017,6,9,0,0,0)\n",
    "    weekday_exits = 0\n",
    "    weekend_exits = 0\n",
    "    weekdays = 0\n",
    "    weekends = 0\n",
    "    for i in range(7):\n",
    "        t1 += dt.timedelta(days = 1)\n",
    "        t2 = t1 + dt.timedelta(days = 1)\n",
    "#         print(t1, getStationRangeRider(bigDict[station], t1, t2), isWeekday(t1))\n",
    "#         print(t1, t2, isWeekday(t1))\n",
    "        if isWeekday(t1):\n",
    "#             print('adding to weekday_exits')\n",
    "            weekday_exits += getStationRangeRider(bigDict[station], t1, t2)\n",
    "            weekdays +=1\n",
    "        else:\n",
    "            weekend_exits += getStationRangeRider(bigDict[station], t1, t2)\n",
    "            weekends+=1\n",
    "#     print(weekdays, weekends)\n",
    "    day = weekday_exits / 5\n",
    "    end = weekend_exits / 2\n",
    "    \n",
    "#     print(day, end)\n",
    "    if end == 0:\n",
    "        return 0\n",
    "    return weekday_exits / 5 - weekend_exits / 2\n",
    "\n",
    "print(getCommuteIndex(('PTH11', 'R545', '14TH STREET')))\n",
    "\n",
    "print(\"Lauren's numbers: 1419, 9507, 0.663\")\n",
    "\n",
    "isWeekday(dt.datetime(2017,6,12,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "totals = []\n",
    "counts_stations.sort(reverse = True)\n",
    "for count, station in counts_stations[:5]:\n",
    "    for each_one in range(count):\n",
    "        totals.append(station)\n",
    "plt.hist(totals, bins = np.arange(-0.5, 5.6, 1), rwidth = 0.5)\n",
    "plt.xticks(fontsize = 7)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('People')\n",
    "plt.title('The most populous stations on 6/12/17')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit 10 - MTA Data Analysis Student Version.ipynb",
   "provenance": [
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}